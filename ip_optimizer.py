import os
import asyncio
import aiohttp
import random
import numpy as np
import time
import socket
import subprocess
import ssl
import http.client
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
from tqdm import tqdm
import urllib3
import ipaddress
import psutil
from typing import List, Dict, Tuple, Any
import json
import hashlib

####################################################
# å¯é…ç½®å‚æ•°ï¼ˆç¨‹åºå¼€å¤´ï¼‰
####################################################
CONFIG = {
    "MODE": "URL_TEST",  # æµ‹è¯•æ¨¡å¼ï¼šPING/TCP/URL_TEST
    "PING_TARGET": "http://www.gstatic.com/generate_204",  # Pingæµ‹è¯•ç›®æ ‡
    "URL_TEST_TARGET": "http://www.gstatic.com/generate_204",  # URLæµ‹è¯•ç›®æ ‡
    "URL_TEST_TIMEOUT": 3,  # URLæµ‹è¯•è¶…æ—¶(ç§’)
    "URL_TEST_RETRY": 2,  # URLæµ‹è¯•é‡è¯•æ¬¡æ•°
    "PING_COUNT": 5,  # Pingæ¬¡æ•°
    "PING_TIMEOUT": 3,  # Pingè¶…æ—¶(ç§’)
    "PORT": 443,  # TCPæµ‹è¯•ç«¯å£
    "RTT_RANGE": "0~800",  # å»¶è¿ŸèŒƒå›´(ms)
    "LOSS_MAX": 10.0,  # æœ€å¤§ä¸¢åŒ…ç‡(%)
    "THREADS": 500,  # å¢åŠ å¹¶å‘çº¿ç¨‹æ•°
    "ASYNC_CONCURRENCY": 1000,  # å¼‚æ­¥å¹¶å‘æ•°
    "IP_POOL_SIZE": 50000,  # IPæ± æ€»å¤§å°
    "TEST_IP_COUNT": 2000,  # å¢åŠ æµ‹è¯•IPæ•°é‡
    "TOP_IPS_LIMIT": 100,  # ç²¾é€‰IPæ•°é‡
    "CLOUDFLARE_IPS_URL": "https://www.cloudflare.com/ips-v4",
    "CUSTOM_IPS_FILE": "custom_ips.txt",  # è‡ªå®šä¹‰IPæ± æ–‡ä»¶è·¯å¾„
    "TCP_RETRY": 3,  # TCPé‡è¯•æ¬¡æ•°
    "SPEED_TIMEOUT": 5,  # æµ‹é€Ÿè¶…æ—¶æ—¶é—´
    "SPEED_URL": "https://speed.cloudflare.com/__down?bytes=10000000",  # æµ‹é€ŸURL
    
    # æ™ºèƒ½IPç”Ÿæˆé…ç½®
    "INTELLIGENT_IP_GENERATION": True,
    "TARGET_REGIONS": ["HK", "SG", "JP", "KR", "US"],
    "REGION_CIDR_MAP": {
        'US': ['104.16.0.0/12', '172.64.0.0/13', '173.245.48.0/20'],
        'HK': ['104.20.0.0/15', '172.67.0.0/16', '104.23.88.0/22'],
        'SG': ['104.24.0.0/14', '172.68.0.0/16', '104.27.0.0/16'],
        'JP': ['104.28.0.0/15', '172.69.0.0/16', '104.18.0.0/15'],
        'KR': ['104.19.0.0/16', '172.70.0.0/16'],
        'DE': ['104.21.0.0/16', '172.67.128.0/17'],
        'GB': ['104.22.0.0/15', '172.68.128.0/17']
    },
    
    # æ–°å¢ï¼šå¤‡ç”¨æµ‹è¯•URLåˆ—è¡¨
    "BACKUP_TEST_URLS": [
        "http://www.gstatic.com/generate_204",
        "http://cp.cloudflare.com/",
        "http://www.cloudflare.com/favicon.ico",
        "http://one.one.one.one/",
        "https://1.1.1.1/",
        "http://www.apple.com/library/test/success.html"
    ],
    
    # åœ°åŒºé…ç½®
    "ENABLE_REGION_MATCHING": True,  # å¯ç”¨åœ°åŒºåŒ¹é…
    "MANUAL_WORKER_REGION": "HK",  # æ‰‹åŠ¨æŒ‡å®šWorkeråœ°åŒº
    "REGION_MAPPING": {
        'US': ['ğŸ‡ºğŸ‡¸ ç¾å›½', 'US', 'United States'],
        'SG': ['ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡', 'SG', 'Singapore'],
        'JP': ['ğŸ‡¯ğŸ‡µ æ—¥æœ¬', 'JP', 'Japan'],
        'HK': ['ğŸ‡­ğŸ‡° é¦™æ¸¯', 'HK', 'Hong Kong'],
        'KR': ['ğŸ‡°ğŸ‡· éŸ©å›½', 'KR', 'South Korea'],
        'DE': ['ğŸ‡©ğŸ‡ª å¾·å›½', 'DE', 'Germany'],
        'SE': ['ğŸ‡¸ğŸ‡ª ç‘å…¸', 'SE', 'Sweden'],
        'NL': ['ğŸ‡³ğŸ‡± è·å…°', 'NL', 'Netherlands'],
        'FI': ['ğŸ‡«ğŸ‡® èŠ¬å…°', 'FI', 'Finland'],
        'GB': ['ğŸ‡¬ğŸ‡§ è‹±å›½', 'GB', 'United Kingdom'],
        'Oracle': ['ç”²éª¨æ–‡', 'Oracle'],
        'DigitalOcean': ['æ•°ç æµ·', 'DigitalOcean'],
        'Vultr': ['Vultr', 'Vultr'],
        'Multacom': ['Multacom', 'Multacom']
    },
    "BACKUP_IPS": [
        {'domain': 'ProxyIP.US.CMLiussss.net', 'region': 'US', 'regionCode': 'US', 'port': 443},
        {'domain': 'ProxyIP.SG.CMLiussss.net', 'region': 'SG', 'regionCode': 'SG', 'port': 443},
        {'domain': 'ProxyIP.JP.CMLiussss.net', 'region': 'JP', 'regionCode': 'JP', 'port': 443},
        {'domain': 'ProxyIP.HK.CMLiussss.net', 'region': 'HK', 'regionCode': 'HK', 'port': 443},
        {'domain': 'ProxyIP.KR.CMLiussss.net', 'region': 'KR', 'regionCode': 'KR', 'port': 443},
        {'domain': 'ProxyIP.DE.CMLiussss.net', 'region': 'DE', 'regionCode': 'DE', 'port': 443},
        {'domain': 'ProxyIP.SE.CMLiussss.net', 'region': 'SE', 'regionCode': 'SE', 'port': 443},
        {'domain': 'ProxyIP.NL.CMLiussss.net', 'region': 'NL', 'regionCode': 'NL', 'port': 443},
        {'domain': 'ProxyIP.FI.CMLiussss.net', 'region': 'FI', 'regionCode': 'FI', 'port': 443},
        {'domain': 'ProxyIP.GB.CMLiussss.net', 'region': 'GB', 'regionCode': 'GB', 'port': 443},
        {'domain': 'ProxyIP.Oracle.cmliussss.net', 'region': 'Oracle', 'regionCode': 'Oracle', 'port': 443},
        {'domain': 'ProxyIP.DigitalOcean.CMLiussss.net', 'region': 'DigitalOcean', 'regionCode': 'DigitalOcean', 'port': 443},
        {'domain': 'ProxyIP.Vultr.CMLiussss.net', 'region': 'Vultr', 'regionCode': 'Vultr', 'port': 443},
        {'domain': 'ProxyIP.Multacom.CMLiussss.net', 'region': 'Multacom', 'regionCode': 'Multacom', 'port': 443}
    ],
    
    # IPåœ°ç†ä½ç½®APIé…ç½®
    "IP_GEO_API": {
        "timeout": 3,
        "retry": 2,
        "enable_cache": True
    },
    
    # æ€§èƒ½ç›‘æ§é…ç½®
    "ENABLE_MONITORING": True,
    "MEMORY_LIMIT_MB": 1024
}

####################################################
# æ–°å¢ï¼šæ€§èƒ½ç›‘æ§ç±»
####################################################
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'network_usage': [],
            'memory_usage': [],
            'scan_speed': [],
            'start_time': time.time()
        }
        self.running = False
        
    def start_monitoring(self):
        """å¯åŠ¨å®æ—¶æ€§èƒ½ç›‘æ§"""
        self.running = True
        
        def monitor_loop():
            while self.running:
                try:
                    # ç½‘ç»œä½¿ç”¨
                    net_io = psutil.net_io_counters()
                    self.metrics['network_usage'].append(net_io.bytes_sent + net_io.bytes_recv)
                    
                    # å†…å­˜ä½¿ç”¨
                    memory = psutil.virtual_memory()
                    self.metrics['memory_usage'].append(memory.percent)
                    
                    # æ‰«æé€Ÿåº¦
                    elapsed = time.time() - self.metrics['start_time']
                    if elapsed > 0:
                        speed = len(self.metrics.get('completed_tasks', [])) / elapsed
                        self.metrics['scan_speed'].append(speed)
                    
                    time.sleep(1)
                except Exception:
                    continue
        
        import threading
        thread = threading.Thread(target=monitor_loop, daemon=True)
        thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.metrics['memory_usage']:
            return "æš‚æ— æ•°æ®"
        
        return {
            'avg_memory_usage': np.mean(self.metrics['memory_usage']),
            'max_memory_usage': np.max(self.metrics['memory_usage']),
            'avg_scan_speed': np.mean(self.metrics['scan_speed']) if self.metrics['scan_speed'] else 0,
            'total_network_usage': self.metrics['network_usage'][-1] if self.metrics['network_usage'] else 0
        }

####################################################
# æ–°å¢ï¼šæ™ºèƒ½IPç”Ÿæˆå™¨
####################################################
class IntelligentIPGenerator:
    def __init__(self, target_regions=None):
        self.target_regions = target_regions or CONFIG["TARGET_REGIONS"]
        self.region_cidr_map = CONFIG["REGION_CIDR_MAP"]
        
    def get_prioritized_subnets(self, subnets):
        """è·å–æŒ‰åœ°åŒºä¼˜å…ˆçº§æ’åºçš„å­ç½‘åˆ—è¡¨"""
        if not CONFIG["INTELLIGENT_IP_GENERATION"]:
            return subnets
            
        prioritized = []
        # é¦–å…ˆæ·»åŠ ç›®æ ‡åœ°åŒºçš„CIDR
        for region in self.target_regions:
            prioritized.extend(self.region_cidr_map.get(region, []))
        
        # æ·»åŠ å…¶ä»–å­ç½‘
        for subnet in subnets:
            if subnet not in prioritized:
                prioritized.append(subnet)
                
        return prioritized
    
    def generate_ip_pool_optimized(self, subnets, pool_size):
        """æµå¼ç”ŸæˆIPï¼Œé¿å…å†…å­˜çˆ†ç‚¸"""
        prioritized_subnets = self.get_prioritized_subnets(subnets)
        
        def ip_generator():
            while True:
                # 70%æ¦‚ç‡é€‰æ‹©ä¼˜å…ˆå­ç½‘ï¼Œ30%æ¦‚ç‡é€‰æ‹©å…¶ä»–å­ç½‘
                if random.random() < 0.7 and prioritized_subnets:
                    subnet = random.choice(prioritized_subnets)
                else:
                    subnet = random.choice(subnets)
                yield self.generate_random_ip(subnet)
        
        # ä½¿ç”¨é›†åˆå»é‡ï¼Œé™åˆ¶å†…å­˜ä½¿ç”¨
        unique_ips = set()
        max_attempts = pool_size * 3  # æœ€å¤§å°è¯•æ¬¡æ•°
        
        for i, ip in enumerate(ip_generator()):
            if len(unique_ips) >= pool_size or i >= max_attempts:
                break
            unique_ips.add(ip)
            
            # å†…å­˜ä¿æŠ¤
            if i % 1000 == 0 and self._check_memory_usage():
                break
        
        return list(unique_ips)
    
    def generate_random_ip(self, subnet):
        """æ ¹æ®CIDRç”Ÿæˆå­ç½‘å†…çš„éšæœºåˆæ³•IP"""
        try:
            network = ipaddress.ip_network(subnet, strict=False)
            network_addr = int(network.network_address)
            broadcast_addr = int(network.broadcast_address)
            first_ip = network_addr + 1
            last_ip = broadcast_addr - 1
            random_ip_int = random.randint(first_ip, last_ip)
            return str(ipaddress.IPv4Address(random_ip_int))
        except Exception:
            base_ip = subnet.split('/')[0]
            parts = base_ip.split('.')
            while len(parts) < 4:
                parts.append(str(random.randint(0, 255)))
            parts = [str(min(255, max(0, int(p)))) for p in parts[:3]] + [str(random.randint(1, 254))]
            return ".".join(parts)
    
    def _check_memory_usage(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        if not CONFIG["ENABLE_MONITORING"]:
            return False
            
        memory = psutil.virtual_memory()
        return memory.percent > 90  # å†…å­˜ä½¿ç”¨è¶…è¿‡90%æ—¶åœæ­¢

####################################################
# æ–°å¢ï¼šå¼‚æ­¥URLæµ‹è¯•å¼•æ“
####################################################
class AsyncURLTester:
    def __init__(self):
        self.connector = None
        self.session = None
        
    async def __aenter__(self):
        # åˆ›å»ºè¿æ¥æ± 
        self.connector = aiohttp.TCPConnector(
            limit=CONFIG["ASYNC_CONCURRENCY"],
            limit_per_host=50,
            ttl_dns_cache=300,
            use_dns_cache=True
        )
        self.session = aiohttp.ClientSession(
            connector=self.connector,
            timeout=aiohttp.ClientTimeout(total=CONFIG["URL_TEST_TIMEOUT"]),
            headers={'User-Agent': 'Mozilla/5.0 (compatible; CF-IP-Tester/1.0)'}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
        if self.connector:
            await self.connector.close()
    
    async def test_ip_batch(self, ip_batch, test_url, progress_callback=None):
        """æ‰¹é‡æµ‹è¯•IP"""
        tasks = []
        for ip in ip_batch:
            task = asyncio.create_task(self._test_single_ip(ip, test_url))
            tasks.append(task)
        
        results = []
        for future in asyncio.as_completed(tasks):
            try:
                result = await future
                results.append(result)
                if progress_callback:
                    progress_callback(1)
            except Exception as e:
                if progress_callback:
                    progress_callback(1)
                continue
        
        return results
    
    async def _test_single_ip(self, ip, test_url):
        """æµ‹è¯•å•ä¸ªIP"""
        parsed_url = urlparse(test_url)
        scheme = parsed_url.scheme
        hostname = parsed_url.hostname
        path = parsed_url.path or '/'
        
        success_count = 0
        total_rtt = 0
        delays = []
        
        for attempt in range(CONFIG["URL_TEST_RETRY"]):
            try:
                start_time = time.time()
                
                # æ„å»ºå®é™…URL
                if parsed_url.port:
                    actual_url = f"{scheme}://{ip}:{parsed_url.port}{path}"
                else:
                    actual_url = f"{scheme}://{ip}{path}"
                
                headers = {'Host': hostname}
                
                async with self.session.get(
                    actual_url,
                    headers=headers,
                    ssl=False
                ) as response:
                    # è¯»å–éƒ¨åˆ†å†…å®¹ç¡®è®¤è¿æ¥
                    await response.read()
                    
                    rtt = (time.time() - start_time) * 1000
                    
                    if response.status < 500:
                        success_count += 1
                        total_rtt += rtt
                        delays.append(rtt)
                
            except (asyncio.TimeoutError, aiohttp.ClientError, OSError):
                continue
            except Exception:
                continue
            
            # çŸ­æš‚é—´éš”
            if attempt < CONFIG["URL_TEST_RETRY"] - 1:
                await asyncio.sleep(0.05)
        
        # è®¡ç®—å¹³å‡å»¶è¿Ÿå’Œä¸¢åŒ…ç‡
        if success_count > 0:
            avg_rtt = total_rtt / success_count
            loss_rate = ((CONFIG["URL_TEST_RETRY"] - success_count) / CONFIG["URL_TEST_RETRY"]) * 100
        else:
            avg_rtt = float('inf')
            loss_rate = 100.0
        
        return (ip, avg_rtt, loss_rate, delays)

####################################################
# ç¼“å­˜å’Œå·¥å…·å‡½æ•°
####################################################
ip_geo_cache = {}

def get_real_ip_region(ip):
    """ä½¿ç”¨çœŸå®çš„åœ°ç†ä½ç½®APIæ£€æµ‹IPåœ°åŒº"""
    if CONFIG["IP_GEO_API"]["enable_cache"] and ip in ip_geo_cache:
        return ip_geo_cache[ip]
    
    apis = [
        {
            'url': f'http://ip-api.com/json/{ip}?fields=status,message,countryCode',
            'field': 'countryCode',
            'check_field': 'status',
            'check_value': 'success'
        },
        {
            'url': f'https://ipapi.co/{ip}/json/',
            'field': 'country_code',
            'check_field': 'country_code',
            'check_value': None
        }
    ]
    
    for api in apis:
        try:
            response = requests.get(api['url'], timeout=CONFIG["IP_GEO_API"]["timeout"])
            if response.status_code == 200:
                data = response.json()
                
                if api['check_value'] is not None:
                    if data.get(api['check_field']) != api['check_value']:
                        continue
                else:
                    if api['check_field'] not in data:
                        continue
                
                country_code = data.get(api['field'])
                if country_code:
                    region_code = map_country_to_region(country_code)
                    
                    if CONFIG["IP_GEO_API"]["enable_cache"]:
                        ip_geo_cache[ip] = region_code
                    
                    return region_code
        except Exception:
            continue
    
    return None

def map_country_to_region(country_code):
    """å°†å›½å®¶ä»£ç æ˜ å°„åˆ°åœ°åŒºä»£ç """
    country_to_region = {
        'US': 'US', 'CA': 'US', 'MX': 'US',
        'SG': 'SG', 'JP': 'JP', 'KR': 'KR', 'TW': 'HK', 'MO': 'HK',
        'CN': 'HK',
        'DE': 'DE', 'FR': 'DE', 'GB': 'GB', 'NL': 'NL', 'SE': 'SE', 
        'FI': 'FI', 'IT': 'DE', 'ES': 'DE', 'CH': 'DE', 'RU': 'DE',
        'AU': 'SG', 'NZ': 'SG',
        'TH': 'SG', 'MY': 'SG', 'ID': 'SG', 'VN': 'SG', 'PH': 'SG',
        'IN': 'SG', 'BD': 'SG', 'PK': 'SG'
    }
    return country_to_region.get(country_code, 'US')

def format_ip_with_region(ip_data, port=None):
    """æ ¼å¼åŒ–IPè¾“å‡ºä¸º ip:ç«¯å£#å›½æ—— åœ°åŒºåç§° æ ¼å¼"""
    if port is None:
        port = CONFIG["PORT"]
    
    region_code = ip_data.get('regionCode', 'Unknown')
    region_info = CONFIG["REGION_MAPPING"].get(region_code, [f"ğŸ‡ºğŸ‡³ æœªçŸ¥({region_code})"])
    flag_and_name = region_info[0]
    
    return f"{ip_data['ip']}:{port}#{flag_and_name}"

def format_ip_list_for_display(ip_list, port=None):
    """æ ¼å¼åŒ–IPåˆ—è¡¨ç”¨äºæ˜¾ç¤ºï¼ˆåŒ…å«åœ°åŒºå’Œçº¯IP:ç«¯å£ï¼‰"""
    if port is None:
        port = CONFIG["PORT"]
    
    formatted_ips = []
    for ip_data in ip_list:
        formatted_ips.append(format_ip_with_region(ip_data, port))
    
    return formatted_ips

def format_ip_list_for_file(ip_list, port=None, include_region=True):
    """æ ¼å¼åŒ–IPåˆ—è¡¨ç”¨äºæ–‡ä»¶ä¿å­˜"""
    if port is None:
        port = CONFIG["PORT"]
    
    formatted_lines = []
    for ip_data in ip_list:
        if include_region:
            region_code = ip_data.get('regionCode', 'Unknown')
            region_info = CONFIG["REGION_MAPPING"].get(region_code, [f"ğŸ‡ºğŸ‡³ æœªçŸ¥({region_code})"])
            flag_and_name = region_info[0]
            formatted_lines.append(f"{ip_data['ip']}:{port}#{flag_and_name}")
        else:
            formatted_lines.append(f"{ip_data['ip']}:{port}")
    
    return formatted_lines

def get_region_by_rtt(rtt, worker_region):
    """æ ¹æ®å»¶è¿Ÿæ™ºèƒ½æ¨æµ‹åœ°åŒº"""
    if not worker_region:
        worker_region = 'HK'
    if rtt < 30:
        return worker_region
    elif rtt < 80:
        nearby_regions = get_nearby_regions(worker_region)
        return random.choice(nearby_regions) if nearby_regions else worker_region
    elif rtt < 150:
        asia_regions = ['SG', 'JP', 'KR', 'HK']
        return random.choice([r for r in asia_regions if r != worker_region])
    else:
        return random.choice(['US', 'DE', 'GB'])

def get_nearby_regions(region):
    """è·å–é‚»è¿‘åœ°åŒºåˆ—è¡¨"""
    nearby_map = {
        'US': ['SG', 'JP', 'HK', 'KR'],
        'SG': ['JP', 'HK', 'KR', 'US'],
        'JP': ['SG', 'HK', 'KR', 'US'],
        'HK': ['SG', 'JP', 'KR', 'US'],
        'KR': ['JP', 'HK', 'SG', 'US'],
        'DE': ['NL', 'GB', 'SE', 'FI'],
        'SE': ['DE', 'NL', 'FI', 'GB'],
        'NL': ['DE', 'GB', 'SE', 'FI'],
        'FI': ['SE', 'DE', 'NL', 'GB'],
        'GB': ['DE', 'NL', 'SE', 'FI']
    }
    return nearby_map.get(region, [])

def get_all_regions_by_priority(region):
    """è·å–æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ‰€æœ‰åœ°åŒº"""
    nearby_regions = get_nearby_regions(region)
    all_regions = ['US', 'SG', 'JP', 'HK', 'KR', 'DE', 'SE', 'NL', 'FI', 'GB']
    return [region, *nearby_regions, *[r for r in all_regions if r != region and r not in nearby_regions]]

def get_smart_region_selection(worker_region, available_ips):
    """æ™ºèƒ½åœ°åŒºé€‰æ‹©ç®—æ³•"""
    if not CONFIG["ENABLE_REGION_MATCHING"] or not worker_region:
        return available_ips
    
    priority_regions = get_all_regions_by_priority(worker_region)
    sorted_ips = []
    
    for region in priority_regions:
        region_ips = [ip for ip in available_ips if ip.get('regionCode') == region]
        sorted_ips.extend(region_ips)
    
    other_ips = [ip for ip in available_ips if ip.get('regionCode') not in priority_regions and ip.get('regionCode') is not None]
    sorted_ips.extend(other_ips)
    
    return sorted_ips

def detect_worker_region():
    """æ£€æµ‹Workeråœ°åŒº"""
    try:
        manual_region = CONFIG["MANUAL_WORKER_REGION"]
        if manual_region and manual_region.strip():
            return manual_region.strip().upper()
        return 'HK'
    except Exception:
        return 'HK'

####################################################
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
####################################################
def init_env():
    """åˆå§‹åŒ–ç¯å¢ƒ"""
    urllib3.disable_warnings()

def fetch_ip_ranges():
    """è·å–IPæ®µ"""
    custom_file = CONFIG["CUSTOM_IPS_FILE"]
    if custom_file and os.path.exists(custom_file):
        print(f"ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰IPæ± æ–‡ä»¶: {custom_file}")
        try:
            with open(custom_file, 'r') as f:
                return [line.strip() for line in f.readlines() if line.strip()]
        except Exception as e:
            print(f"ğŸš¨ è¯»å–è‡ªå®šä¹‰IPæ± å¤±è´¥: {e}")
    
    url = CONFIG["CLOUDFLARE_IPS_URL"]
    try:
        res = requests.get(url, timeout=10, verify=False)
        return res.text.splitlines()
    except Exception as e:
        print(f"ğŸš¨ è·å–Cloudflare IPæ®µå¤±è´¥: {e}")
    return []

def validate_test_urls():
    """éªŒè¯æµ‹è¯•URLçš„å¯ç”¨æ€§"""
    print("ğŸ” éªŒè¯æµ‹è¯•URLå¯ç”¨æ€§...")
    for test_url in CONFIG["BACKUP_TEST_URLS"]:
        try:
            start_time = time.time()
            response = requests.get(test_url, timeout=5, verify=False)
            rtt = (time.time() - start_time) * 1000
            if response.status_code < 500:
                print(f"âœ… {test_url} - å¯ç”¨ (å»¶è¿Ÿ: {rtt:.1f}ms, çŠ¶æ€ç : {response.status_code})")
                return test_url
        except Exception as e:
            print(f"âŒ {test_url} - é”™è¯¯: {e}")
    return CONFIG["BACKUP_TEST_URLS"][0]

def speed_test(ip):
    """é€Ÿåº¦æµ‹è¯•"""
    url = CONFIG["SPEED_URL"]
    timeout = CONFIG["SPEED_TIMEOUT"]
    try:
        parsed_url = urlparse(url)
        host = parsed_url.hostname
        start_time = time.time()
        response = requests.get(
            url, headers={'Host': host}, timeout=timeout, verify=False, stream=True
        )
        total_bytes = 0
        for chunk in response.iter_content(chunk_size=8192):
            total_bytes += len(chunk)
            if time.time() - start_time > timeout:
                break
        duration = time.time() - start_time
        speed_mbps = (total_bytes * 8 / duration) / 1e6 if duration > 0 else 0
        return speed_mbps
    except Exception:
        return 0.0

def enhance_ip_with_region_info(ip_list, worker_region):
    """ä¸ºIPåˆ—è¡¨æ·»åŠ çœŸå®çš„åœ°åŒºä¿¡æ¯"""
    enhanced_ips = []
    print("ğŸŒ æ­£åœ¨æ£€æµ‹IPçœŸå®åœ°ç†ä½ç½®...")
    
    with tqdm(total=len(ip_list), desc="IPåœ°ç†ä½ç½®", unit="IP") as pbar:
        for ip_data in ip_list:
            ip = ip_data[0]
            rtt = ip_data[1]
            loss = ip_data[2]
            speed = ip_data[3] if len(ip_data) > 3 else 0
            
            region_code = get_real_ip_region(ip)
            if not region_code:
                region_code = get_region_by_rtt(rtt, worker_region)
            
            region_name = CONFIG["REGION_MAPPING"].get(region_code, [f"ğŸ‡ºğŸ‡³ æœªçŸ¥({region_code})"])[0]
            
            enhanced_ip = {
                'ip': ip,
                'rtt': rtt,
                'loss': loss,
                'speed': speed,
                'regionCode': region_code,
                'regionName': region_name,
                'isp': "Cloudflare"
            }
            enhanced_ips.append(enhanced_ip)
            pbar.update(1)
    
    return enhanced_ips

def print_config_info():
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("="*60)
    print(f"{'ğŸš€ IPç½‘ç»œä¼˜åŒ–å™¨ v2.0 (å¼‚æ­¥å¢å¼ºç‰ˆ)':^60}")
    print("="*60)
    print(f"æµ‹è¯•æ¨¡å¼: {CONFIG['MODE']}")
    worker_region = detect_worker_region()
    print(f"Workeråœ°åŒº: {CONFIG['REGION_MAPPING'].get(worker_region, [worker_region])[0]}")
    print(f"åœ°åŒºåŒ¹é…: {'å¯ç”¨' if CONFIG['ENABLE_REGION_MATCHING'] else 'ç¦ç”¨'}")
    print(f"æ™ºèƒ½IPç”Ÿæˆ: {'å¯ç”¨' if CONFIG['INTELLIGENT_IP_GENERATION'] else 'ç¦ç”¨'}")
    print(f"å¼‚æ­¥å¹¶å‘æ•°: {CONFIG['ASYNC_CONCURRENCY']}")
    print(f"æµ‹è¯•IPæ•°é‡: {CONFIG['TEST_IP_COUNT']}")
    print("="*60 + "\n")

def save_results(all_results, passed_ips, enhanced_results, sorted_ips):
    """ä¿å­˜ç»“æœæ–‡ä»¶"""
    os.makedirs('results', exist_ok=True)
    
    # ä¿å­˜å„ç§æ ¼å¼çš„ç»“æœæ–‡ä»¶
    with open('results/all_ips.txt', 'w') as f:
        f.write("\n".join([ip[0] for ip in all_results]))
    
    with open('results/passed_ips.txt', 'w') as f:
        f.write("\n".join([ip[0] for ip in passed_ips]))
    
    with open('results/full_results.csv', 'w') as f:
        f.write("IP,å»¶è¿Ÿ(ms),ä¸¢åŒ…ç‡(%),é€Ÿåº¦(Mbps),åœ°åŒºä»£ç ,åœ°åŒºåç§°,ISP\n")
        for ip_data in enhanced_results:
            f.write(f"{ip_data['ip']},{ip_data['rtt']:.2f},{ip_data['loss']:.2f},{ip_data['speed']:.2f},{ip_data['regionCode']},{ip_data['regionName']},{ip_data['isp']}\n")
    
    with open('results/top_ips.txt', 'w', encoding='utf-8') as f:
        formatted_lines = format_ip_list_for_file(sorted_ips, include_region=True)
        f.write("\n".join(formatted_lines))
    
    with open('results/top_ips_plain.txt', 'w', encoding='utf-8') as f:
        formatted_lines = format_ip_list_for_file(sorted_ips, include_region=False)
        f.write("\n".join(formatted_lines))
    
    # ä¿å­˜åœ°åŒºç»Ÿè®¡
    region_stats = {}
    for ip_data in enhanced_results:
        region = ip_data['regionCode']
        if region not in region_stats:
            region_stats[region] = {'count': 0, 'avg_rtt': 0, 'avg_speed': 0, 'region_name': ip_data['regionName']}
        region_stats[region]['count'] += 1
        region_stats[region]['avg_rtt'] += ip_data['rtt']
        region_stats[region]['avg_speed'] += ip_data['speed']
    
    for region in region_stats:
        if region_stats[region]['count'] > 0:
            region_stats[region]['avg_rtt'] /= region_stats[region]['count']
            region_stats[region]['avg_speed'] /= region_stats[region]['count']
    
    with open('results/region_stats.csv', 'w', encoding='utf-8') as f:
        f.write("åœ°åŒºä»£ç ,åœ°åŒºåç§°,IPæ•°é‡,å¹³å‡å»¶è¿Ÿ(ms),å¹³å‡é€Ÿåº¦(Mbps)\n")
        for region, stats in region_stats.items():
            f.write(f"{region},{stats['region_name']},{stats['count']},{stats['avg_rtt']:.2f},{stats['avg_speed']:.2f}\n")

def display_final_results(sorted_ips, enhanced_results, monitor):
    """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
    # åœ°åŒºç»Ÿè®¡
    region_stats = {}
    for ip_data in enhanced_results:
        region = ip_data['regionCode']
        if region not in region_stats:
            region_stats[region] = {'count': 0, 'avg_rtt': 0, 'avg_speed': 0, 'region_name': ip_data['regionName']}
        region_stats[region]['count'] += 1
        region_stats[region]['avg_rtt'] += ip_data['rtt']
        region_stats[region]['avg_speed'] += ip_data['speed']
    
    for region in region_stats:
        if region_stats[region]['count'] > 0:
            region_stats[region]['avg_rtt'] /= region_stats[region]['count']
            region_stats[region]['avg_speed'] /= region_stats[region]['count']
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "="*60)
    print(f"{'ğŸ”¥ æµ‹è¯•ç»“æœç»Ÿè®¡':^60}")
    print("="*60)
    
    if CONFIG["ENABLE_MONITORING"]:
        stats = monitor.get_stats()
        print(f"ğŸƒ æ€§èƒ½ç»Ÿè®¡: å¹³å‡é€Ÿåº¦ {stats['avg_scan_speed']:.1f} IP/ç§’, å†…å­˜ä½¿ç”¨ {stats['avg_memory_usage']:.1f}%")
    
    print(f"ğŸ“Š IPç»Ÿè®¡: æ€»æ•° {len(enhanced_results)}, ç²¾é€‰ {len(sorted_ips)}")
    
    print(f"\nğŸŒ åœ°åŒºåˆ†å¸ƒ:")
    for region, stats in sorted(region_stats.items(), key=lambda x: x[1]['count'], reverse=True):
        print(f"  {stats['region_name']}: {stats['count']}ä¸ªIP, å¹³å‡å»¶è¿Ÿ{stats['avg_rtt']:.1f}ms, å¹³å‡é€Ÿåº¦{stats['avg_speed']:.1f}Mbps")
    
    if sorted_ips:
        print(f"\nğŸ†ã€æœ€ä½³IP TOP10 (å¸¦åœ°åŒºä¿¡æ¯)ã€‘")
        formatted_top_ips = format_ip_list_for_display(sorted_ips[:10])
        for i, formatted_ip in enumerate(formatted_top_ips, 1):
            print(f"{i}. {formatted_ip}")
        
        print(f"\nğŸ†ã€æœ€ä½³IP TOP10 (çº¯IP:ç«¯å£)ã€‘")
        for i, ip_data in enumerate(sorted_ips[:10], 1):
            plain_ip = f"{ip_data['ip']}:{CONFIG['PORT']}"
            print(f"{i}. {plain_ip}")
    
    print("="*60)
    print("âœ… ç»“æœå·²ä¿å­˜è‡³ results/ ç›®å½•")

####################################################
# ä¸»ç¨‹åºå…¥å£
####################################################
async def main_async():
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–ç¯å¢ƒå’Œç›‘æ§
    init_env()
    monitor = PerformanceMonitor()
    if CONFIG["ENABLE_MONITORING"]:
        monitor.start_monitoring()
    
    try:
        # 1. éªŒè¯æµ‹è¯•URL
        best_url = validate_test_urls()
        CONFIG["URL_TEST_TARGET"] = best_url
        print(f"ğŸ¯ ä½¿ç”¨æµ‹è¯•URL: {best_url}")
        
        # 2. æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        print_config_info()
        
        # 3. è·å–IPæ®µå¹¶ç”Ÿæˆæ™ºèƒ½IPæ± 
        subnets = fetch_ip_ranges()
        if not subnets:
            print("âŒ æ— æ³•è·å–IPæ®µï¼Œç¨‹åºç»ˆæ­¢")
            return
        
        ip_generator = IntelligentIPGenerator()
        test_ip_count = CONFIG["TEST_IP_COUNT"]
        
        print(f"ğŸ”§ æ­£åœ¨æ™ºèƒ½ç”Ÿæˆ {test_ip_count} ä¸ªæµ‹è¯•IP...")
        test_ip_pool = ip_generator.generate_ip_pool_optimized(subnets, test_ip_count)
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(test_ip_pool)} ä¸ªæµ‹è¯•IP")
        
        # 4. å¼‚æ­¥URLæµ‹è¯•
        print(f"ğŸš€ å¼€å§‹å¼‚æ­¥URLæµ‹è¯• (å¹¶å‘æ•°: {CONFIG['ASYNC_CONCURRENCY']})...")
        
        batch_size = CONFIG["ASYNC_CONCURRENCY"]
        all_results = []
        
        with tqdm(total=len(test_ip_pool), desc="ğŸŒ å¼‚æ­¥URLæµ‹è¯•", unit="IP") as pbar:
            async with AsyncURLTester() as tester:
                for i in range(0, len(test_ip_pool), batch_size):
                    batch = test_ip_pool[i:i + batch_size]
                    batch_results = await tester.test_ip_batch(
                        batch, 
                        CONFIG["URL_TEST_TARGET"],
                        progress_callback=lambda x: pbar.update(x)
                    )
                    all_results.extend(batch_results)
        
        # 5. ç­›é€‰åˆæ ¼IP
        rtt_min, rtt_max = map(int, CONFIG["RTT_RANGE"].split('~'))
        loss_max = CONFIG["LOSS_MAX"]
        passed_ips = [
            ip_data for ip_data in all_results
            if rtt_min <= ip_data[1] <= rtt_max and ip_data[2] <= loss_max
        ]
        print(f"âœ… å»¶è¿Ÿæµ‹è¯•å®Œæˆ: æ€»æ•° {len(all_results)}, é€šè¿‡ {len(passed_ips)}")
        
        if not passed_ips:
            print("âŒ æ²¡æœ‰é€šè¿‡å»¶è¿Ÿæµ‹è¯•çš„IPï¼Œç¨‹åºç»ˆæ­¢")
            return
        
        # 6. æµ‹é€Ÿé˜¶æ®µ
        print("ğŸ“Š å¼€å§‹æµ‹é€Ÿé˜¶æ®µ...")
        full_results = []
        with ThreadPoolExecutor(max_workers=CONFIG["THREADS"]) as executor:
            future_to_ip = {executor.submit(speed_test, ip_data[0]): ip_data for ip_data in passed_ips}
            with tqdm(total=len(passed_ips), desc="ğŸ“Š æµ‹é€Ÿè¿›åº¦", unit="IP") as pbar:
                for future in as_completed(future_to_ip):
                    try:
                        ip_data = future_to_ip[future]
                        speed = future.result()
                        full_results.append((*ip_data, speed))
                    except Exception:
                        continue
                    finally:
                        pbar.update(1)
        
        # 7. åœ°åŒºæ£€æµ‹å’Œæ™ºèƒ½æ’åº
        worker_region = detect_worker_region()
        enhanced_results = enhance_ip_with_region_info(full_results, worker_region)
        
        if CONFIG["ENABLE_REGION_MATCHING"] and worker_region:
            print(f"ğŸ”§ æ­£åœ¨æŒ‰åœ°åŒºä¼˜å…ˆçº§æ’åº...")
            region_sorted_ips = get_smart_region_selection(worker_region, enhanced_results)
            sorted_ips = sorted(
                region_sorted_ips,
                key=lambda x: (-x['speed'], x['rtt'], x['loss'])
            )[:CONFIG["TOP_IPS_LIMIT"]]
        else:
            sorted_ips = sorted(
                enhanced_results,
                key=lambda x: (-x['speed'], x['rtt'])
            )[:CONFIG["TOP_IPS_LIMIT"]]
        
        # 8. ä¿å­˜ç»“æœ
        save_results(all_results, passed_ips, enhanced_results, sorted_ips)
        
        # 9. æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        display_final_results(sorted_ips, enhanced_results, monitor)
        
    finally:
        monitor.stop_monitoring()

if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main_async())
